{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageColor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourModel:\n",
    "    def __init__(self, x = 0, y = 0, w = 0, h = 0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск искр от сварки на кадре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_for_color(frame, lower, upper) -> ContourModel | None:    \n",
    "    hsv_frame = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    mask = cv.inRange(hsv_frame, lower, upper)\n",
    "    target = cv.bitwise_and(hsv_frame, hsv_frame, mask=mask)\n",
    "    blur = cv.GaussianBlur(mask, (0, 0), sigmaX=10, sigmaY=10)\n",
    "    \n",
    "    ret, thresh = cv.threshold(blur, 40, 255, 0)\n",
    "    \n",
    "    cont, hier = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    if len(cont) != 0:\n",
    "        c = max(cont, key=cv.contourArea)\n",
    "        cv.drawContours(target, c, -1, 255, 3)\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        return ContourModel(x, y, w, h)\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контуры движущихся предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_movements(frame1, frame2) -> (cv.Mat, list[ContourModel]):\n",
    "    bodies = []\n",
    "    \n",
    "    diff = cv.absdiff(frame1, frame2)\n",
    "    diff_gray = cv.cvtColor(diff, cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(diff_gray, (0, 0), sigmaX=3, sigmaY=3)\n",
    "\n",
    "    _, thresh = cv.threshold(blur, 25, 255, 0)\n",
    "    dilated = cv.dilate(thresh, None, iterations=20)   \n",
    "\n",
    "\n",
    "    conts, _ = cv.findContours(dilated, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)  \n",
    "\n",
    "    for cont in conts:\n",
    "        x, y, w, h = cv.boundingRect(cont)\n",
    "        area = cv.contourArea(cont)\n",
    "        if area < 40000 and area > 3000:\n",
    "            bodies.append(ContourModel(x, y, w, h))\n",
    "               \n",
    "    return (diff, bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedFrame:\n",
    "    def __init__(self, is_sparks : bool, is_humans : bool):\n",
    "        self.is_sparks = is_sparks\n",
    "        self.is_humans = is_humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выявляет наличие людей в двух кадрах, наличие искр\n",
    "def analyze_two_frames(frame1 : cv.Mat, frame2 : cv.Mat) -> ParsedFrame:\n",
    "    is_sparks = False\n",
    "    is_humans = False\n",
    "\n",
    "    frame1 = cv.resize(frame1, (int(frame1.shape[1] * 0.7), int(frame1.shape[0] * 0.7)))\n",
    "    frame2 = cv.resize(frame2, (int(frame2.shape[1] * 0.7), int(frame2.shape[0] * 0.7)))\n",
    "\n",
    "    #movements[0] - результат \"абсолютного вычитания\" двух кадров\n",
    "    #movements[1] - список ContourModel, координаты прямоугольника с человеком\n",
    "    movements = detect_movements(frame1, frame2)\n",
    "    sides = [0, 0, frame1.shape[0], frame1.shape[1]]\n",
    "\n",
    "    if len(movements[1]):\n",
    "        is_humans = True\n",
    "\n",
    "    for cont in movements[1]:\n",
    "        containers = [cont.x, cont.y, cont.x + cont.w, cont.y + cont.h]\n",
    "\n",
    "        # Жадно увеличиваем область вокруг каждого найденного человека, чтобы увеличить вероятность нахождения искр вокруг него\n",
    "        for i, side in enumerate(sides):\n",
    "            if side and i in [0, 1] and containers[i] * 0.9 >= side:\n",
    "                containers[i] = int(0.9 * containers[i])\n",
    "            elif containers[i] * 1.1 <= side:\n",
    "                containers[i] = int(1.1 * containers[i])\n",
    "\n",
    "        # Два разных метода получения контуров искр. Для болгарки используется динамический метод(основывается на \n",
    "        # \"абсолютном вычитании\" двух кадров + цвет), для сварки статический (на основе цвета)\n",
    "\n",
    "        #movements[0] - результат \"абсолютного вычитания\" двух кадров  \n",
    "        cropped_bolg = movements[0][containers[1] : containers[-1],\n",
    "                         containers[0] : containers[2]]\n",
    "        cropped_svar = frame1[containers[1]: containers[-1],\n",
    "                              containers[0]: containers[2]]\n",
    "        \n",
    "        # Цвет искр болгарки и от сварки отличаются, сварка более синяя, в то время как болгарка желто-белая\n",
    "        svar_spark = detect_for_color(\n",
    "            cropped_svar, np.array([85, 125, 180]), np.array([140, 225, 255]))\n",
    "        bolg_spark = detect_for_color(\n",
    "            cropped_bolg, np.array([50, 0, 135]), np.array([180, 255, 255]))\n",
    "        \n",
    "        \n",
    "        if svar_spark or bolg_spark:\n",
    "            is_sparks = True\n",
    "        \n",
    "    return ParsedFrame(is_sparks, is_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class States:\n",
    "    Useful = 1\n",
    "    Forced = 2\n",
    "    Stand = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезная - наличие искр\n",
    "\n",
    "Вынужденная - наличие людей, без искр\n",
    "\n",
    "Простой - отсутсвие людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './learn_video.mp4'\n",
    "exclude_times = [ (7200, 8100), (14400, 16200), (25200, 26100), (36000, 36900)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalModel:\n",
    "    def __init__(self, time : int, state : int):\n",
    "        self.time = time\n",
    "        self.state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг видео\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "prev_state = States.Forced\n",
    "last_good = 0\n",
    "\n",
    "DELAY = 30\n",
    "times : list[EvalModel] = []\n",
    "bad_temp : list[EvalModel] = []\n",
    "while True:\n",
    "    ret1, frame1 = cap.read()\n",
    "    ret2, frame2 = cap.read()\n",
    "    if not (ret1 and ret2):\n",
    "        break\n",
    "\n",
    "    # Алгоритм определения задержки рабочего на 30 секунд. При увеличении константы, уменьшается шанс простоя\n",
    "    curr_time = cap.get(cv.CAP_PROP_POS_MSEC) // 1000\n",
    "\n",
    "    for exc in exclude_times:\n",
    "        if curr_time >= exc[0] and curr_time <= exc[1]:\n",
    "            continue\n",
    "\n",
    "    data = analyze_two_frames(frame1=frame1,\n",
    "                              frame2=frame2)\n",
    "\n",
    "    if data.is_sparks:\n",
    "        if curr_time - last_good >= DELAY:\n",
    "            bad_temp = [EvalModel(eval_m.time, States.Stand) for eval_m in bad_temp]\n",
    "        times.extend(bad_temp)\n",
    "        bad_temp.clear()\n",
    "\n",
    "        prev_state = States.Useful\n",
    "        times.append(EvalModel(curr_time, prev_state))\n",
    "\n",
    "        last_good = curr_time\n",
    "\n",
    "    elif data.is_humans and not data.is_sparks:\n",
    "        if curr_time - last_good >= 30:\n",
    "            bad_temp = [EvalModel(eval_m.time, States.Stand)\n",
    "                        for eval_m in bad_temp]\n",
    "            \n",
    "        times.extend(bad_temp)\n",
    "        bad_temp.clear()\n",
    "\n",
    "        prev_state = States.Forced\n",
    "        times.append(EvalModel(curr_time, prev_state))\n",
    "\n",
    "        last_good = curr_time\n",
    "    else:\n",
    "        bad_temp.append(EvalModel(curr_time, States.Stand))                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка выходных данных. Слияние кадров n-ой секунды в один кадр, в зависимости от медианы состояний\n",
    "st = [[i.state, int(i.time)] for i in times]\n",
    "\n",
    "prev_result = []\n",
    "temp = []\n",
    "class_t = 0\n",
    "j = 0\n",
    "for j in range(len(st)):\n",
    "    if st[j][1] != class_t:\n",
    "        prev_result.append(temp)\n",
    "        temp = []\n",
    "\n",
    "        class_t = st[j][1]\n",
    "    temp.append(st[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "# Константа влияющая на точность определения полезной работы, Много и мало плохо\n",
    "USEFUL_CONST = 3\n",
    "for stamp in prev_result:\n",
    "    in_line = [i[0] for i in stamp]\n",
    "    if in_line.count(1) > USEFUL_CONST:\n",
    "        result.append([1, stamp[0][1]])\n",
    "    else:\n",
    "        mean = int(np.mean(in_line))\n",
    "        result.append([mean, stamp[0][1]])\n",
    "        \n",
    "\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline = [i[0] for i in result]\n",
    "useful = inline.count(1)\n",
    "force = inline.count(2)\n",
    "stand = inline.count(3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "states = ['Useful', 'Force', 'Stand']\n",
    "counts = [useful / len(inline) * 100, force / len(inline) * 100, stand / len(inline) * 100  ]\n",
    "\n",
    "\n",
    "ax.set_ylabel('Count of states (in percent)')\n",
    "ax.set_xlabel('States')\n",
    "ax.bar(states, counts)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Утилиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture('../examples/learn_video.mp4')\n",
    "\n",
    "cnt = 0\n",
    "modes = [ord('q'), ord('s'), ord('n')]\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    cv.imshow('asd', img)\n",
    "\n",
    "    inp = cv.waitKey(1) & 0xFF\n",
    "    while inp not in modes:\n",
    "        inp = cv.waitKey(1) & 0xFF\n",
    "\n",
    "    if inp == ord('s'):\n",
    "        cv.imwrite(f'./tests/{cnt}.jpg', img)\n",
    "        cnt += 1\n",
    "    if inp == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./tests/01_out.jpg')\n",
    "detect_for_color(img, np.array([60, 0, 100]), np.array([180, 255, 255]))\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('./tests/01_out.jpg')\n",
    "\n",
    "# Create a window\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# Create trackbars for color change\n",
    "# Hue is from 0-179 for Opencv\n",
    "cv2.createTrackbar('HMin', 'image', 0, 179, nothing)\n",
    "cv2.createTrackbar('SMin', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('VMin', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('HMax', 'image', 0, 179, nothing)\n",
    "cv2.createTrackbar('SMax', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('VMax', 'image', 0, 255, nothing)\n",
    "\n",
    "# Set default value for Max HSV trackbars\n",
    "cv2.setTrackbarPos('HMax', 'image', 179)\n",
    "cv2.setTrackbarPos('SMax', 'image', 255)\n",
    "cv2.setTrackbarPos('VMax', 'image', 255)\n",
    "\n",
    "# Initialize HSV min/max values\n",
    "hMin = sMin = vMin = hMax = sMax = vMax = 0\n",
    "phMin = psMin = pvMin = phMax = psMax = pvMax = 0\n",
    "\n",
    "while (1):\n",
    "    # Get current positions of all trackbars\n",
    "    hMin = cv2.getTrackbarPos('HMin', 'image')\n",
    "    sMin = cv2.getTrackbarPos('SMin', 'image')\n",
    "    vMin = cv2.getTrackbarPos('VMin', 'image')\n",
    "    hMax = cv2.getTrackbarPos('HMax', 'image')\n",
    "    sMax = cv2.getTrackbarPos('SMax', 'image')\n",
    "    vMax = cv2.getTrackbarPos('VMax', 'image')\n",
    "\n",
    "    # Set minimum and maximum HSV values to display\n",
    "    lower = np.array([hMin, sMin, vMin])\n",
    "    upper = np.array([hMax, sMax, vMax])\n",
    "\n",
    "    # Convert to HSV format and color threshold\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    prev_result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Print if there is a change in HSV value\n",
    "    if ((phMin != hMin) | (psMin != sMin) | (pvMin != vMin) | (phMax != hMax) | (psMax != sMax) | (pvMax != vMax)):\n",
    "        print(\"(hMin = %d , sMin = %d, vMin = %d), (hMax = %d , sMax = %d, vMax = %d)\" % (\n",
    "            hMin, sMin, vMin, hMax, sMax, vMax))\n",
    "        phMin = hMin\n",
    "        psMin = sMin\n",
    "        pvMin = vMin\n",
    "        phMax = hMax\n",
    "        psMax = sMax\n",
    "        pvMax = vMax\n",
    "\n",
    "    # Display result image\n",
    "    cv2.imshow('image', prev_result)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
